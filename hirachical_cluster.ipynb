{
 "metadata": {
  "name": "",
  "signature": "sha256:6ac68056513e9329d83fdb934cf494774f3e85544820a98b337b02d546164181"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import logging\n",
      "from logging.config import fileConfig\n",
      "__author__ = 'Jimin.Zhou'\n",
      "from datetime import *\n",
      "import traceback\n",
      "import ConfigParser\n",
      "import io\n",
      "import pickle\n",
      "import sys\n",
      "import pymongo\n",
      "import mysql.connector\n",
      "from scipy.sparse import *\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from math import *\n",
      "from numpy import *\n",
      "from sklearn.cluster import AffinityPropagation\n",
      "import re\n",
      "from itertools import chain\n",
      "import pandas as pd\n",
      "import re\n",
      "from collections import defaultdict\n",
      "import itertools\n",
      "from scipy.cluster.hierarchy import *\n",
      "import jieba"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_db = mysql.connector.connect(host=\"db-news01-dev.datayes.com\", db='news', user=\"news_app\",\n",
      "                              passwd=\"lKTOAIyoewzvCyc\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class News:\n",
      "    def __init__(self,newsId, newsTitle, newsContent, publishTime, storyID=-1):\n",
      "        \"\"\"\n",
      "\n",
      "        :type self: object\n",
      "        \"\"\"\n",
      "        self.newsID = newsId\n",
      "        self.newsTitle = newsTitle\n",
      "        self.newsContent = newsContent\n",
      "        self.publishTime = publishTime\n",
      "        self.storyID = -1\n",
      "        self.isMain = False\n",
      "        self.storyID = storyID"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jieba.load_userdict('dict.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Building Trie..., from /usr/local/Anaconda/lib/python2.7/site-packages/jieba/dict.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "DEBUG:jieba:Building Trie..., from /usr/local/Anaconda/lib/python2.7/site-packages/jieba/dict.txt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "loading model from cache /tmp/jieba.cache\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "DEBUG:jieba:loading model from cache /tmp/jieba.cache\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "loading model cost 1.49771881104 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "DEBUG:jieba:loading model cost 1.49771881104 seconds.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Trie has been built succesfully.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "DEBUG:jieba:Trie has been built succesfully.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_tokenizer(s):\n",
      "    regExp = u\"[^(\\u4e00-\\u9fa50-9)]\"\n",
      "    s = re.sub(regExp, ' ', s)\n",
      "    ll = jieba.cut(s)\n",
      "    return ' '.join(ll).split()\n",
      "def getNewsByPiriod(mysql_db,st_publish_time, ed_publish_time):\n",
      "    selectSql = \"\"\"select news_id, news_title, news_body, news_publish_time\n",
      "        from news_detail_backup\n",
      "        where group_id != -1\n",
      "        and isActive = 1\n",
      "        and news_tag = 0\n",
      "        and source_type in ('news_pgenius','news_nutch','news_spider')\n",
      "        and news_publish_time > '%s'\n",
      "        and news_publish_time < '%s'\"\"\"%(st_publish_time,ed_publish_time)\n",
      "    cursor = mysql_db.cursor()\n",
      "    cursor.execute(selectSql)\n",
      "    news = []\n",
      "    for nn in cursor:\n",
      "        #News(nn[0], nn[1], nn[2], nn[3])\n",
      "        nws = News(nn[0], nn[1], nn[2], nn[3])\n",
      "        news.append(nws)\n",
      "    return news\n",
      "def find(x):\n",
      "    global unset\n",
      "    p = x\n",
      "    while (unset[p]>=0):\n",
      "        p=unset[p]\n",
      "    while (x!=p):\n",
      "        t = unset[x]\n",
      "        unset[x] = p\n",
      "        x = t\n",
      "    return x\n",
      "def unionSet(x,y):\n",
      "    global unset\n",
      "    x = find(x)\n",
      "    y = find(y)\n",
      "    if (x == y):\n",
      "        return\n",
      "    if unset[x] < unset[y]:\n",
      "        unset[x] = unset[x] + unset[y]\n",
      "        unset[y] = x\n",
      "    else:\n",
      "        unset[y] = unset[y] + unset[x];\n",
      "        unset[x] = y\n",
      "def cluster(dataList,indx,tol):\n",
      "    global cosineDist\n",
      "    global newsInfoAll\n",
      "    distMat = cosineDist[dataList][:,dataList]\n",
      "    ind = list(itertools.combinations(range(len(dataList)),2))\n",
      "    distMat = 1.0- distMat.todense()\n",
      "    distMat[distMat<0]=0.0\n",
      "    distMatCon = [distMat[ii] for ii in ind]\n",
      "    linkJ = average(distMatCon)\n",
      "    clusterJ = fcluster(linkJ, 0.7, 'distance')\n",
      "    for ind in range(len(clusterJ)):\n",
      "       # news_cls_res[dataList[ind]]=clusterJ[ind]*tol+indx\n",
      "        newsInfoAll.Catg[dataList[ind]]=clusterJ[ind]*tol+indx\n",
      "def classify(all_news):\n",
      "    global idfVector\n",
      "    global wordsDF\n",
      "    global unset\n",
      "    global cosineDist\n",
      "    global newsInfoAll\n",
      "    cv = CountVectorizer(analyzer=my_tokenizer)\n",
      "    cntContentRes = cv.fit_transform(all_news)\n",
      "    cntContentRes = cntContentRes.astype(int)\n",
      "\n",
      "    feature = cv.get_feature_names()\n",
      "    rep = cntContentRes.sum(axis=0).A[0]\n",
      "    ind = rep > 1\n",
      "    feature = array(feature)[rep>1]\n",
      "    #\u6ca1\u6709\u5171\u7528\u7684\u7279\u5f81\uff0c\u5b8c\u5168\u4e0d\u540c\n",
      "    if sum(array(ind))==0:\n",
      "        return range(len(all_news)), range(len(all_news))\n",
      "    cntContentRes = cntContentRes[:, ind]\n",
      "\n",
      "    wdDF_subset = []\n",
      "    for wd in feature:\n",
      "        if wordsDF.has_key(wd):\n",
      "            wdDF_subset.append(wordsDF[wd])\n",
      "        else:\n",
      "            wdDF_subset.append(0)\n",
      "    wdIdf = []\n",
      "    maxDF = max(wdDF_subset)\n",
      "    for x in wdDF_subset:\n",
      "        if x > 0:\n",
      "            wdIdf.append(log((maxDF+0.0)/x))\n",
      "        else:\n",
      "            wdIdf.append(0)\n",
      "    wdidfDia = lil_matrix((len(wdIdf),len(wdIdf)))\n",
      "    wdidfDia.setdiag(wdIdf)\n",
      "    \n",
      "    cntContentRes = cntContentRes.tocsr()\n",
      "    idfVector = cntContentRes*wdidfDia\n",
      "#     distMatJ = idfVector*idfVector.T\n",
      "#     dia = distMatJ.diagonal()\n",
      "#     dia = map(lambda x:1.0/math.sqrt(x) if x!=0 else 1, dia)\n",
      "#     bfDia = lil_matrix((len(dia),len(dia)))\n",
      "#     bfDia.setdiag(dia)\n",
      "#     cosineDist = bfDia*distMatJ*bfDia\n",
      "#     filterM = cosineDist > 0.3\n",
      "#     cosineDistSt = cosineDist.multiply(filterM)\n",
      "#     cosineDistSt.setdiag(zeros(cosineDistSt.shape[0]))\n",
      "#     noZeroInd = zip(cosineDistSt.nonzero()[0],cosineDistSt.nonzero()[1])\n",
      "#     indexMap = sorted(list(set(chain.from_iterable(noZeroInd))))\n",
      "#     filteredNum = len(indexMap)\n",
      "\n",
      "\n",
      "#     map2Index = dict(zip(indexMap,range(filteredNum)))\n",
      "#     unset = [-1]*filteredNum\n",
      "#     for elm in noZeroInd:\n",
      "#         if elm[0] < elm[1]:\n",
      "#             unionSet(map2Index[elm[0]], map2Index[elm[1]])\n",
      "#     nodeLocMap = {}\n",
      "#     for ind in range(filteredNum):\n",
      "#         nodeLocMap[indexMap[ind]] = find(ind)\n",
      "#     groupedDistMat = defaultdict(list)\n",
      "#     for key, value in sorted(nodeLocMap.iteritems()):\n",
      "#         groupedDistMat[value].append(key)\n",
      "\n",
      "#     groupNum = len(groupedDistMat.values())\n",
      "#     for i in range(groupNum):\n",
      "#         dataList = groupedDistMat.values()[i]\n",
      "#         cluster(dataList,i,groupNum)\n",
      "#     newsInfoAll.ix[newsInfoAll.Catg!=-1].sort('Catg').to_csv('/root/data/classifyNewsContent7.txt',encoding = 'utf-8',sep = '\\t',index = False)\n",
      "#     # af = AffinityPropagation(affinity = 'precomputed',preference=2).fit(array(distMatJ.todense()))\n",
      "    # cluster_centers_indices = af.cluster_centers_indices_\n",
      "    # labels = af.labels_\n",
      "    # res = labels\n",
      "    # #preference==2\u7684bug\u5904\u7406\n",
      "    # if not isinstance(res[0], int):\n",
      "    #     return zeros(len(all_news)), [0]\n",
      "    # return res,cluster_centers_indices\n",
      "def doClassifyAllnews(news):\n",
      "    global newsInfoAll\n",
      "    news_contents = [nn.newsContent for nn in news]\n",
      "    news_titles = [nn.newsTitle for nn in news]\n",
      "    newsInfoAll = pd.DataFrame({'Title':news_titles,'content':news_contents,'Catg':-1})\n",
      "    if len(news_contents) > 1:\n",
      "        #res,cluster_centers_indices =\n",
      "        classify(news_contents)\n",
      "def doJobBatchWeek(news_db):\n",
      "    # global mongo_base\n",
      "    y = 2014\n",
      "    m = 3\n",
      "    d = 1\n",
      "    initTime = datetime(y,m,d)+timedelta(7)\n",
      "    news = getNewsByPiriod(news_db, datetime(y,m,d), initTime)\n",
      "    return news"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wordsDF = pickle.load(file('contentWordsDf.ser'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news = doJobBatchWeek(news_db)\n",
      "doClassifyAllnews(news)\n",
      "mat = 1/sqrt(idfVector.multiply(idfVector).sum(axis=1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shape(idfVector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "(19137, 114951)"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "diaa = lil_matrix((shape(idfVector)[0],shape(idfVector)[0]))\n",
      "diaa.setdiag(mat)\n",
      "mat = diaa*idfVector\n",
      "mat = mat.todok()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = file('day7.pk', 'r') \n",
      "mat=pickle.load(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = file('day7.pk', 'w') \n",
      "pickle.dump(mat.todok(), f)\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkContext\n",
      "from pyspark.serializers import PickleSerializer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#CLUSTER_URL=\"spark://sh-prd-hadoop-nn01:7077\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pyspark import SparkConf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conf = SparkConf()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conf.setMaster(\"yarn-client\").setAppName(\"hirachical\").set(\"spark.akka.frameSize\", \"1000\").set(\"spark.broadcast.factory\",\"org.apache.spark.broadcast.TorrentBroadcastFactory\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "<pyspark.conf.SparkConf at 0x52c75990>"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conf.getAll()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "[(u'spark.default.parallelism', u'8'),\n",
        " (u'spark.executor.memory', u'8g'),\n",
        " (u'spark.driver.memory', u'4g'),\n",
        " (u'spark.executor.instances', u'9'),\n",
        " (u'spark.yarn.historyServer.address', u'sh-prd-hadoop-nn01:18080'),\n",
        " (u'spark.eventLog.enabled', u'true'),\n",
        " (u'spark.cores.max', u'144'),\n",
        " (u'spark.submit.pyFiles', u''),\n",
        " (u'spark.home', u'/opt/spark-1.0.1-bin-hadoop2'),\n",
        " (u'spark.driver.host', u'10.21.234.167'),\n",
        " (u'spark.akka.frameSize', u'1000'),\n",
        " (u'spark.app.name', u'hirachical'),\n",
        " (u'spark.eventLog.dir', u'hdfs://sh-prd-hadoop-nn01:8020/sparklog'),\n",
        " (u'spark.master', u'yarn-client'),\n",
        " (u'spark.broadcast.factory',\n",
        "  u'org.apache.spark.broadcast.TorrentBroadcastFactory')]"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'sc' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-5-f154e069615b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc = SparkContext(conf = conf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "--args is deprecated. Use --arg instead.\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newsDataParal = sc.parallelize(mat.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newsDataParal.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "3854175"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "aaa = sc.parallelize([1,2,3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graphData = sc.broadcast(mat.items()) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "MemoryError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-31-b7ffb885b96b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraphData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/usr/local/spark/clients/spark/python/pyspark/context.pyc\u001b[0m in \u001b[0;36mbroadcast\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \"\"\"\n\u001b[0;32m    369\u001b[0m         \u001b[0mpickleSer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mpickled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickleSer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[0mjbroadcast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         return Broadcast(jbroadcast.id(), value, jbroadcast,\n",
        "\u001b[1;32m/usr/local/spark/clients/spark/python/pyspark/serializers.pyc\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    277\u001b[0m     \"\"\"\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m     \u001b[0mloads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcPickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mMemoryError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graphData = graphData.filter(lambda ((x,y),z):z>0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataMapped = graphData.map(lambda ((x,y),z): (y,(x,z)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataMapped.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "442247"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Starting here"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataGroupped = dataMapped.groupByKey()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataGroupped.unpersist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "PythonRDD[39] at RDD at PythonRDD.scala:37"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def agg(wd, ar):\n",
      "    arr = []\n",
      "    for n in ar:\n",
      "        for m in ar:\n",
      "            if n[0]<m[0]:\n",
      "                tt = n[1]*m[1]\n",
      "                if tt>0.003:\n",
      "                    arr.append(((n[0],m[0]),tt))\n",
      "    return arr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalData = dataGroupped.flatMap(lambda (x,y):agg(x,y)).cache()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalData.unpersist()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "PythonRDD[40] at RDD at PythonRDD.scala:37"
       ]
      }
     ],
     "prompt_number": 74
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "finalData.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "2317266"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = finalData.reduceByKey(lambda x,y:x+y).filter(lambda (x,y): y > 0.3).cache()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cc = arr.collect()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "noZeroInd = [elm[0] for elm in cc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexMap = sorted(list(set(chain.from_iterable(noZeroInd))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arrLeft = arr.filter(lambda ((x,y),z): x in indexMap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arrLeft"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 83,
       "text": [
        "PythonRDD[16] at RDD at PythonRDD.scala:37"
       ]
      }
     ],
     "prompt_number": 83
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(arrLeft.collect())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 100,
       "text": [
        "15"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filteredNum = len(indexMap)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map2Index = dict(zip(indexMap,range(filteredNum)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unset = [-1]*filteredNum\n",
      "for elm in noZeroInd:\n",
      "    if elm[0] < elm[1]:\n",
      "        unionSet(map2Index[elm[0]], map2Index[elm[1]])\n",
      "nodeLocMap = {}\n",
      "for ind in range(filteredNum):\n",
      "    nodeLocMap[indexMap[ind]] = find(ind)\n",
      "groupedDistMat = defaultdict(list)\n",
      "for key, value in sorted(nodeLocMap.iteritems()):\n",
      "    groupedDistMat[value].append(key)\n",
      "\n",
      "groupNum = len(groupedDistMat.values())\n",
      "# for i in range(groupNum):\n",
      "#     dataList = groupedDistMat.values()[i]\n",
      "#     cluster(dataList,i,groupNum)\n",
      "#newsInfoAll.ix[newsInfoAll.Catg!=-1].sort('Catg').to_csv('/root/data/classifyNewsContent7.txt',encoding = 'utf-8',sep = '\\t',index = False)\n",
      "# af = AffinityPropagation(affinity = 'precomputed',preference=2).fit(array(distMatJ.todense()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lenOfIslands = [len(x) for x in groupedDistMat.values()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "groupedNews = sc.parallelize(list(groupedDistMat.iteritems()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 108
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calDist(i,j):\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cluster(newsInd):\n",
      "    \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "groupedNews.mapValues(lambda newsInd : cluster(newsInd)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 110,
       "text": [
        "PythonRDD[28] at RDD at PythonRDD.scala:37"
       ]
      }
     ],
     "prompt_number": 110
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(groupNum):\n",
      "    dataList = groupedDistMat.values()[i]\n",
      "    cluster(dataList,i,groupNum)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#     unset = [-1]*filteredNum\n",
      "#     for elm in noZeroInd:\n",
      "#         if elm[0] < elm[1]:\n",
      "#             unionSet(map2Index[elm[0]], map2Index[elm[1]])\n",
      "#     nodeLocMap = {}\n",
      "#     for ind in range(filteredNum):\n",
      "#         nodeLocMap[indexMap[ind]] = find(ind)\n",
      "#     groupedDistMat = defaultdict(list)\n",
      "#     for key, value in sorted(nodeLocMap.iteritems()):\n",
      "#         groupedDistMat[value].append(key)\n",
      "\n",
      "#     groupNum = len(groupedDistMat.values())\n",
      "#     for i in range(groupNum):\n",
      "#         dataList = groupedDistMat.values()[i]\n",
      "#         cluster(dataList,i,groupNum)\n",
      "#     newsInfoAll.ix[newsInfoAll.Catg!=-1].sort('Catg').to_csv('/root/data/classifyNewsContent7.txt',encoding = 'utf-8',sep = '\\t',index = False)\n",
      "#     # af = AffinityPropagation(affinity = 'precomputed',preference=2).fit(array(distMatJ.todense()))\n",
      "    # cluster_centers_indices = af.cluster_centers_indices_\n",
      "    # labels = af.labels_\n",
      "    # res = labels\n",
      "    # #preference==2\u7684bug\u5904\u7406\n",
      "    # if not isinstance(res[0], int):\n",
      "    #     return zeros(len(all_news)), [0]\n",
      "    # return res,cluster_centers_indices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(cc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "8339"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#sc.stop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#arr.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}